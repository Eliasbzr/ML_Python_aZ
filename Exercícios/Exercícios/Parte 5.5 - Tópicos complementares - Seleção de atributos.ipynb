{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPK58/mUTem9oPGc0KeGDj9"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"e1TOzrpdTD49"},"source":["---\n","\n","Reconecte ao Drive."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"60gkOY_gTDjz"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TW1LzILHTfAO"},"outputs":[],"source":["import os\n","DRIVE_DIRECTORY = \"curso_ml\"\n","DRIVE_DIRECTORY = os.path.join(\"/content/drive/MyDrive\", DRIVE_DIRECTORY)"]},{"cell_type":"markdown","source":["---"],"metadata":{"id":"SqoVMD-4bZgM"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import pickle\n","\n","from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier\n","from sklearn.feature_selection import VarianceThreshold\n","from sklearn.metrics import accuracy_score, classification_report\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder, MinMaxScaler"],"metadata":{"id":"AMtbDA25gJfo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Seleção de atributos"],"metadata":{"id":"-DVyBt2zWW5k"}},{"cell_type":"markdown","source":["### Base de dados cobertura vegetal"],"metadata":{"id":"jqlgbz18XPcF"}},{"cell_type":"markdown","metadata":{"id":"YoXf3ysejEU3"},"source":["Neste exercício você vai mais uma vez utilizar a base de dados cobertura vegetal."]},{"cell_type":"markdown","source":["Carregue o arquivo csv salvo na pasta do Drive. Visualize o DataFrame resultante."],"metadata":{"id":"QAjjBeYPWslB"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"okyhICqUgmUw"},"outputs":[],"source":["base = ___"]},{"cell_type":"code","source":["___"],"metadata":{"id":"Ld8BPysmNDmP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Desta vez você vai remover as colunas categóricas, pois a variância é mais informativa para atributos numéricos."],"metadata":{"id":"btO8auNDgi1K"}},{"cell_type":"markdown","source":["Primeiro, separe o nome das colunas em uma variável `colunas`, mas lembre-se de remover as 3 últimas colunas (que correspondem às 2 variáveis categóricas, mais a variável alvo)."],"metadata":{"id":"7oGFmshkhtDZ"}},{"cell_type":"code","source":["columns = base.___[:___]\n","columns"],"metadata":{"id":"IuQE8LVAhsdS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Agora crie as variáveis `X` e `y`, no formato de NumPy array, mas não inclua as variáveis categóricas em `X`."],"metadata":{"id":"XjU7WzrmiW5u"}},{"cell_type":"code","source":["X = ___\n","y = ___"],"metadata":{"id":"saFVXapsiTyM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Exiba os valores de X."],"metadata":{"id":"DFXAUABri799"}},{"cell_type":"code","source":["___"],"metadata":{"id":"1d9BQNRai5nj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Crie um scaler do tipo `MinMaxScaler`, e aplique aos dados de `X`. Exiba o resultado."],"metadata":{"id":"QwkysKVBirpy"}},{"cell_type":"code","source":["scaler = ___\n","X = ___\n","___"],"metadata":{"id":"TeCn1o7hih1H"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Codifique os dados de `y` utilizando `LabelEncoder`."],"metadata":{"id":"vtMtev9hjgfX"}},{"cell_type":"code","source":["encoder = ___\n","y = ___\n","___"],"metadata":{"id":"8bQawhWYjgSg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Por fim, salve as variáveis `X` e `y` na pasta do Drive, você vai utilizá-los nos exercícios seguintes."],"metadata":{"id":"RPRCEyXUqyWT"}},{"cell_type":"code","source":["with open(os.path.join(DRIVE_DIRECTORY, ___), ___) as f:\n","    ___((___, ___), f)"],"metadata":{"id":"7aey2nnhqxu-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Variância"],"metadata":{"id":"zb2YdBx1j0MH"}},{"cell_type":"markdown","source":["Exiba a variância dos dados preditores. DICA: ao invés de um implementar um loop, você pode usar o método `var` com o parâmetro `axis=0`, que vai calcular a variância nas colunas."],"metadata":{"id":"i1IwKMxGkE-t"}},{"cell_type":"code","source":["X.___(axis=0)"],"metadata":{"id":"VRR1ECQLjnxa"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Perceba que temos 10 valores, correspondentes às 10 colunas numéricas do dataset."],"metadata":{"id":"X7k8iGWikTYs"}},{"cell_type":"markdown","source":["Crie um seletor do tipo `VarianceThreshold` utilizando `threshold=0.02`. Exiba o `shape` do resultado."],"metadata":{"id":"MNlhpseVkrBV"}},{"cell_type":"code","source":["selector = ___\n","X_variance = ___\n","___"],"metadata":{"id":"Kr8Xt1EFkaK1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Exiba as variâncias armazenadas no seletor."],"metadata":{"id":"8cLLt102k4Yt"}},{"cell_type":"code","source":["___"],"metadata":{"id":"ScRInfYJkn6p"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Perceba que os resultados são os mesmos que você calculou antes."],"metadata":{"id":"MUh0Z9mVk7At"}},{"cell_type":"markdown","source":["Recupere os índices das colunas que foram selecionadas."],"metadata":{"id":"SL6WPLugk-ku"}},{"cell_type":"code","source":["indices = np.___(___)\n","indices"],"metadata":{"id":"VhA-QX6xk3fP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Qual o nome das colunas selecionadas?"],"metadata":{"id":"LeMKesNclK1I"}},{"cell_type":"code","source":["___"],"metadata":{"id":"7iQSNlpglM3x"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Agora, utilize os dados em `X_variance` e `y` para separar os dados em split de treinamento, e de teste (com `test_size=0.25`)."],"metadata":{"id":"ph2R0OwFlbWS"}},{"cell_type":"code","source":["X_train, X_test, y_train, y_test = ___(___, ___, ___, random_state=0)"],"metadata":{"id":"EfSmMTIulOFG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Crie uma instância do tipo `RandomForestClassifier`, com os argumentos padrão e `random_state=0`. Treine o algoritmo com os dados de treinamento."],"metadata":{"id":"ZlHstDA2mNqt"}},{"cell_type":"code","source":["tree_classifier = ___\n","___"],"metadata":{"id":"e2Q9twzmmA1o"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Faça predições para os dados de teste, e calcule a acurácia."],"metadata":{"id":"hmEOKTK4mYbM"}},{"cell_type":"code","source":["___"],"metadata":{"id":"uhm_yDm3kwZz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["___"],"metadata":{"id":"Ary3da_QkwZ0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Veja que neste caso, o algoritmo ficou um pouco pior que aquele treinado na **Parte 1**. Isso indica que, por mais que tenhamos acentuado os atributos com maior variância, e potencialmente por isso mais poder discriminativo, tanto os atributos de menor variância quanto os atributos categóricos têm influência não desprezível na classificação das árvores."],"metadata":{"id":"XChfTLiFmbrZ"}},{"cell_type":"markdown","source":["### Extra tree"],"metadata":{"id":"rl2b7Pd6myxF"}},{"cell_type":"markdown","source":["Agora crie e treine uma instância do seletor `ExtraTreesClassifier`. Utilize todos os dados, ou seja, as variáveis `X`e `y`, na fase de seleção de atributos."],"metadata":{"id":"qa3IXOOqm5jg"}},{"cell_type":"code","source":["selector = ___\n","___"],"metadata":{"id":"UkTKTH0lmMRL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Exiba as importâncias determinadas pelo algoritmo."],"metadata":{"id":"AtUg_TVonv7n"}},{"cell_type":"code","source":["___"],"metadata":{"id":"rZQlWyBZnWAr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Com auxílio do NumPy, recupere os índices com importância maior que $0.07$."],"metadata":{"id":"KhOTuiqcoBRJ"}},{"cell_type":"code","source":["indices = ___\n","___"],"metadata":{"id":"lM5hBk4tnzA1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Que atributos foram selecionados?"],"metadata":{"id":"MFVuCLwTnymi"}},{"cell_type":"code","source":["___"],"metadata":{"id":"xi2k2V2ZoLMQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Filtre os dados em `X` para recuperar somente os índices selecionados. Agora, observe que `indices` é uma tupla contendo um elemento, que é o array com os índices, então nesta construção você deve utilizar `indices[0]` para recuperar os índices dentro da tupla."],"metadata":{"id":"ctyC2AvUoO2v"}},{"cell_type":"code","source":["X_tree = X[:, ind___[___]]"],"metadata":{"id":"qn7vxmMroNFt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Mais uma vez, separe os dados `X_tree` e `y` em split de treinamento, e de teste (com `test_size=0.25`)."],"metadata":{"id":"iVHxEpZ7pMyW"}},{"cell_type":"code","source":["___"],"metadata":{"id":"ASf22D23pMyW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Crie uma instância do tipo `RandomForestClassifier`, com os argumentos padrão e `random_state=0`. Treine o algoritmo com os dados de treinamento."],"metadata":{"id":"tRYY8uX5pMyW"}},{"cell_type":"code","source":["tree_classifier = ___\n","___"],"metadata":{"id":"Semeg_V5pMyW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Faça predições para os dados de teste, e calcule a acurácia."],"metadata":{"id":"1lRheD3JpMyW"}},{"cell_type":"code","source":["___"],"metadata":{"id":"EXSspsQdpMyX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["___"],"metadata":{"id":"x4mMVG50pMyX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Mais uma vez esta seleção se mostrou pior que utilizar todos os dados, mas ficou um pouco melhor que a seleção baseada em variância."],"metadata":{"id":"p3kuGk8qpavS"}}]}